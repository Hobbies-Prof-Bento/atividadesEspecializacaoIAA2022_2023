############# ROTINAS DE ESTATISTICA APLICADA II #########

########################## PARTE 1 #######################

#install.packages("plyr")
#install.packages("readr")
#install.packages("dplyr")
#install.packages("caret")
#install.packages("ggplot2")
#install.packages("repr")
#install.packages("glmnet")

library(plyr)
library(readr)
library(dplyr)
library(caret)
library(ggplot2)
library(repr)
library(glmnet)

load("C:/iaa/wage.RData")

dat <- wage
glimpse(dat)
gc()
#### Data partioning #######

set.seed(302) 

index = sample(1:nrow(dat), 0.8*nrow(dat)) 

train = dat[index,] # Create the training data 
test = dat[-index,] # Create the test data

dim(train)
dim(test)

#### Scaling variables ########

cols = c('husage', 'husearns', 'huseduc', 'hushrs', 'earns',
         'age', 'educ', 'hrwage')

pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))

train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])

summary(train)
summary(test)

###### Regressão Ridge  ###########
## Regressão ridge reduz os coeficientes

cols_reg = c('husage', 'husearns', 'huseduc', 'hushrs', 
             'earns', 'age', 'educ', 'hrwage','husblck',
             'hushisp', 'kidge6', 'black', 'hispanic',
             'union', 'kidlt6')

dummies <- dummyVars(hrwage ~ husage+husearns+huseduc+hushrs+ 
                     earns+age+educ+husblck+hushisp+kidge6+
                     black+hispanic+union+kidlt6, 
                     data = dat[,cols_reg])

train_dummies = predict(dummies, newdata = train[,cols_reg])

test_dummies = predict(dummies, newdata = test[,cols_reg])

print(dim(train_dummies)); print(dim(test_dummies))

# A regressão Ridge é uma extensão da regressão linear em 
# que a função de perda é modificada para minimizar a 
# complexidade do modelo. Essa modificação é feita 
# adicionando um parâmetro de penalidade equivalente ao 
# quadrado da magnitude dos coeficientes.

# Uma das principais diferenças entre os modelos de regressão
# linear e regularizada é que o último envolve o ajuste de
# um hiperparâmetro, lambda. O código executa o modelo 
# glmnet() várias vezes para diferentes valores de lambda. 
# Podemos automatizar essa tarefa de encontrar o valor lambda
# ideal usando a função cv.glmnet(). Isso é feito usando as
# linhas de código abaixo.

# A função perda é dada por:
# Loss function = OLS+lambda*summation(squared coefficient
# values)
# Lambda é o parâmetro de penalidade que selecionamos

# The data for model

x = as.matrix(train_dummies)
y_train = train$hrwage

x_test = as.matrix(test_dummies)
y_test = test$hrwage

### The optimal lambda value ########
lambdas <- 10^seq(2, -3, by = -.1)
ridge_lamb <- cv.glmnet(x, y_train, alpha = 0, 
                      lambda = lambdas)
best_lambda_ridge <- ridge_lamb$lambda.min
best_lambda_ridge

ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, 
                   family = 'gaussian', 
                   lambda = best_lambda_ridge)

summary(ridge_reg)

# Obtendo os valores dos parâmetros

ridge_reg[["beta"]]

# Compute R^2 from true and predicted values
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))
  
  # Model performance metrics
  data.frame(
    RMSE = RMSE,
    Rsquare = R_square
  )
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = best_lambda_ridge,
                             newx = x)
eval_results(y_train, predictions_train, train)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = best_lambda_ridge, 
                            newx = x_test)
eval_results(y_test, predictions_test, test)

# Prediction for our example

# Como os valores de entrada no modelo estão normalizados,
# temos de normalizar também os dados que queremos prever
# Observe que as variáveis dummies não sofrem normalização

#Para:
# husage = 40 anos
husage = (40-pre_proc_val[["mean"]][["husage"]])/
                          pre_proc_val[["std"]][["husage"]]
# husearns = 551
husearns = (551-pre_proc_val[["mean"]][["husearns"]])/
                          pre_proc_val[["std"]][["husearns"]]

# huseduc = 13
huseduc = (13-pre_proc_val[["mean"]][["huseduc"]])/
                          pre_proc_val[["std"]][["huseduc"]]

# husblck = 0
husblck = 0

# hushisp = 0
hushisp = 0

# hushrs = 40
hushrs = (40-pre_proc_val[["mean"]][["hushrs"]])/
                          pre_proc_val[["std"]][["hushrs"]]

# kidge6 = 0
kidge6 = 0

# earns = 355.5
earns = (355.5-pre_proc_val[["mean"]][["earns"]])/
                          pre_proc_val[["std"]][["earns"]]

# age = 37 anos 
age = (37-pre_proc_val[["mean"]][["age"]])/
                          pre_proc_val[["std"]][["age"]]

# black = 0
black = 0

# educ = 13
educ = (13-pre_proc_val[["mean"]][["educ"]])/
                          pre_proc_val[["std"]][["educ"]]

# hispanic = 0
hispanic = 0

# union = 0
union = 0

# kidlt6 = 0
kidlt6 = 0

# Construindo uma matriz com os dados para predição

our_pred = as.matrix(data.frame(husage=husage, 
                                husearns=husearns,
                                huseduc=huseduc,
                                husblck=husblck,
                                hushisp=hushisp,
                                hushrs=hushrs,
                                kidge6=kidge6,
                                earns=earns,
                                age=age,
                                black=black,
                                educ=educ,
                                hispanic=hispanic,
                                union=union,
                                kidlt6=kidlt6))
# Fazendo a predição

predict_our_ridge <- predict(ridge_reg, s = best_lambda_ridge, 
                     newx = our_pred)
predict_our_ridge

# O resultado é uma informação normalizada, vamos 
# convertê-la em valor nominal, compatível com a base de 
# dados original
 
wage_pred_ridge=(predict_our_ridge*
                   pre_proc_val[["std"]][["hrwage"]])+
                   pre_proc_val[["mean"]][["hrwage"]]
wage_pred_ridge

# Confident intervals for our example

n <- nrow(train)
m <- wage_pred_ridge
s <- pre_proc_val[["std"]][["hrwage"]]
dam <- s/sqrt(n)
CIlwr_ridge <- m + (qnorm(0.025))*dam
CIupr_ridge <- m - (qnorm(0.025))*dam 

CIlwr_ridge
CIupr_ridge

##### Regressão Lasso ####
## Leva a zero os coeficientes não significativos

# A regressão Lasso, ou o Operador de Encolhimento Absoluto
# Mínimo e Seleção, também é uma modificação da regressão
# linear. No lasso, a função de perda é modificada para
# minimizar a complexidade do modelo, limitando a soma dos
# valores absolutos dos coeficientes do modelo 
# (também chamado de l1-norm).
# O uso de uma restrição l1-norm força alguns valores de
# peso a zero para permitir que outros coeficientes assumam
# valores diferentes de zero.

# A função perda é dada por:
# Loss function = OLS+lambda*summation(absolute values of
# the magnitude of the coefficients)

# Escolhendo  melhor lambda como parâmetro

lambdas <- 10^seq(2, -3, by = -.1)

# Setting alpha = 1 implements lasso regression
lasso_lamb <- cv.glmnet(x, y_train, alpha = 1, 
                       lambda = lambdas, 
                       standardize = TRUE, nfolds = 5)

# Best 
best_lambda_lasso <- lasso_lamb$lambda.min 
best_lambda_lasso

lasso_model <- glmnet(x, y_train, alpha = 1, 
                      lambda = best_lambda_lasso, 
                      standardize = TRUE)

# Visualizando os parâmetros calculados

lasso_model[["beta"]]

# Fazendo as predições a avaliando o modelo lasso nas bases 
# de treino e teste

predictions_train <- predict(lasso_model, s = best_lambda_lasso,
                             newx = x)
eval_results(y_train, predictions_train, train)

predictions_test <- predict(lasso_model, s = best_lambda_lasso, 
                            newx = x_test)
eval_results(y_test, predictions_test, test)

## Prediction for our example

# Fazendo a predição baseada nos mesmos parâmetros da 
# regressão ridge

predict_our_lasso <- predict(lasso_model, s = best_lambda_lasso, 
                          newx = our_pred)
predict_our_lasso

# Novamente, a informação que retorna é normalizada, temos
# de convertê-la em valor compatível com a base de dados 
# original

wage_pred_lasso=(predict_our_lasso*
                   pre_proc_val[["std"]][["hrwage"]])+
                   pre_proc_val[["mean"]][["hrwage"]]
wage_pred_lasso

# Confident intervals for our example

n <- nrow(train)
m <- wage_pred_lasso
s <- pre_proc_val[["std"]][["hrwage"]]
dam <- s/sqrt(n)
CIlwr_lasso <- m + (qnorm(0.025))*dam
CIupr_lasso <- m - (qnorm(0.025))*dam 

CIlwr_lasso
CIupr_lasso

########### Regressão ElasticNet ###########################

# A regressão ElasticNet combina as propriedades de regressão
# Ridge e lasso. Ele funciona penalizando o modelo usando 
# tanto a l2-norm quanto a l1-norm. O modelo pode ser 
# facilmente construído usando o pacote caret, que seleciona
# automaticamente o valor ideal dos parâmetros.

# Set training control
train_cont <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 5,
                           search = "random",
                           verboseIter = TRUE)

# Train the model

# Note que aqui não temos o parâmetro alpha, porque a
# regressão elasticnet vai selecioná-lo automaticamente com
# valor entre 0 e 1; Para a regressão ridge alpha=0 e 
# lasso alpha=1
# Na elasticnet o par?metro lambda também é encontrado por
# cross-validation

elastic_reg <- train(hrwage ~ husage+husearns+huseduc+hushrs+ 
                       earns+age+educ+husblck+hushisp+kidge6+
                       black+hispanic+union+kidlt6,
                     data = train,
                     method = "glmnet",
                     tuneLength = 10,
                     trControl = train_cont)

# Best tuning parameter
elastic_reg$bestTune

# And the parameters are:

elastic_reg[["finalModel"]][["beta"]]

# Fazendo as predições nas bases de treino e teste e
# avaliando o modelo

# Make predictions on training set
predictions_train <- predict(elastic_reg, x)
eval_results(y_train, predictions_train, train) 

# Make predictions on test set
predictions_test <- predict(elastic_reg, x_test)
eval_results(y_test, predictions_test, test)

## Prediction for our example

predict_our_elastic <- predict(elastic_reg,our_pred)
predict_our_elastic

# Novamente, a informação que retorna é normalizada, temos
# de convertê-la em valor compatível com a base de dados 
# original

wage_pred_elastic=(predict_our_elastic*
                     pre_proc_val[["std"]][["hrwage"]])+
                     pre_proc_val[["mean"]][["hrwage"]]
wage_pred_elastic

# Confident intervals for our example

n <- nrow(train)
m <- wage_pred_elastic
s <- pre_proc_val[["std"]][["hrwage"]]
dam <- s/sqrt(n)
CIlwr_elastic <- m + (qnorm(0.025))*dam
CIupr_elastic <- m - (qnorm(0.025))*dam 

CIlwr_elastic
CIupr_elastic

###################### FIM DA PARTE 1 #######################

###################### INÍCIO PARTE 2 #######################

################# Testes não Paramétricos ###################

###### One-Sample Wilcoxon Signed Rank Test #################

# Preparando os dados

# Usaremos um conjunto de dados de exemplo contendo o peso
# de 10 ratos. Queremos saber se o peso mediano dos camundongos
# difere de 25g?

load("C:/iaa/data_rats.Rdata")

# Sumário estatístico do peso

summary(data_rats$weight)


# Visualize seus dados usando box plots

library(ggpubr)
ggboxplot(data_rats$weight, 
          ylab = "Weight (g)", xlab = FALSE,
          ggtheme = theme_minimal())

mean(data_rats$weight)
median(data_rats$weight)

# Calcular teste de Wilcoxon de uma amostra

# Queremos saber se o peso mediano dos ratos difere de 25g
# (teste bicaudal)

# One-sample wilcoxon test
res <- wilcox.test(data_rats$weight, mu = 25)
res 

# H0: peso dos ratos é igual estatisticamente a 25g
# HA: peso dos ratos é estisticamente diferente de 25g

# O p-value do teste é 0,001953, que é menor que o nível de 
# significância alfa = 0.05. Podemos rejeitar a hipótese 
# nula e concluir que o peso mediano dos camundongos é 
# significativamente diferente de 25g com um p-value de
# p = 0,001953.

# se você deseja testar se o peso mediano dos camundongos é 
# inferior a 25g (teste unicaudal), use a seguinte função:

wilcox.test(data_rats$weight, mu = 25,
            alternative = "less")

# H0: o peso mediano dos ratos é maior que 25g
# HA: o peso mediano dos ratos é menor que 25g

# data:  data_rats$weight
# V = 0, p-value = 0.0009766
# alternative hypothesis: true location is less than 25

# Como p-value < 0.05, rejeita-se H0, o peso mediano dos ratos
# é menor que 25g

###### se você quiser testar se o peso mediano dos camundongos 
# é maior que 25g (teste unicaudal), use a seguinte função:

wilcox.test(data_rats$weight, mu = 25,
            alternative = "greater")

# H0: o peso mediano dos ratos é menor que 25g
# HA: o peso mediano dos ratos é maior que 25g

# data:  data_rats$weight
# V = 0, p-value = 1
# alternative hypothesis: true location is greater than 25

# Como p-value > 0.05 aceita-se H0, o peso mediano dos ratos
# é menor que 25g



###### Unpaired Two-Samples Wilcoxon Test para ############# 
#### independencia de grupos/amostras desemparelhadas ###### 
###############(ou não emparelhadas)########################


# Preparando os dados

# Dados em dois vetores numéricos

women_weight <- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4,
                  48.8, 48.5)

men_weight <- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3,
                62.4) 

# Criar um data frame

weight <- data.frame( 
  group = rep(c("Woman", "Man"), each = 9),
  weight = c(women_weight,  men_weight)
)


# Queremos saber se o peso mediano das mulheres difere do
# peso mediano dos homens.

# Sumário estatístico

library(dplyr)

group_by(weight, group) %>%
  summarise(
    count = n(),
    median = median(weight, na.rm = TRUE),
    IQR = IQR(weight, na.rm = TRUE)
  )

#Visualize seus dados usando box plots

# Plote "weight" por groupo

library("ggpubr")
ggboxplot(weight, x = "group", y = "weight", 
          color = "group", palette=c("#00AFBB", "#E7B800"),
          ylab = "Weight", xlab = "Groups")

# Teste se o peso mediano dos homens é igual ao peso mediano
# das mulheres
# O teste é sempre feito com relação ao disposto no vetor de
# teste, no caso do último para o primeiro - No vetor: 
# Man contra Woman

res <- wilcox.test(weight ~ group, data = weight,
                   exact = FALSE)
res

# O p-value do teste é 0,02712, que é menor que o nível de
# significância alfa = 0,05. Podemos concluir que o peso 
# mediano dos homens é significativamente diferente do peso
# mediano das mulheres.

# Observe que:
# se você quiser testar se o peso mediano dos homens é menor
# que o peso mediano das mulheres, use a seguinte função:

wilcox.test(weight ~ group, data = weight, 
            exact = FALSE, alternative = "less")

# Como p-value > 0.05 o peso mediano dos homens não é menor
# que o peso mediano das mulheres

# se você quiser testar se o peso mediano dos homens é maior
# que o peso mediano das mulheres, use a seguinte função:

wilcox.test(weight ~ group, data = weight,
            exact = FALSE, alternative = "greater")

# como p-value < 0.05 o peso mediano dos homens é maior que
# o peso mediano das mulheres

# Então conclui-se que o peso mediano dos homens é maior que
# o peso mediano das mulheres


############################################################
########Teste de Wilcoxon para amostras pareadas ###########

# Carregando os dados

# Usaremos um conjunto de dados de exemplo, que contém o
# peso de 10 ratos antes e depois do tratamento.

load ("C:/iaa/paired_weight.Rdata")

# Queremos saber se existe alguma diferença significativa
# nos pesos medianos antes e depois do tratamento?

# Calcule estatísticas resumidas por grupos:

library("dplyr")
group_by(paired_weight, group) %>%
  summarise(
    count = n(),
    median = median(weight, na.rm = TRUE),
    IQR = IQR(weight, na.rm = TRUE)
  )

# Visualize seus dados usando box plots
# Plote os pesos por grupo

library("ggpubr")

ggboxplot(paired_weight, x = "group", y = "weight", 
          color = "group", palette=c("blue", "red"),
          order = c("before", "after"),
          ylab = "Weight", xlab = "Groups")


# Plote os dados emparelhados:

# Subconjunto de dados de peso antes do tratamento

before <- subset(paired_weight,  group == "before", weight,
                 drop = TRUE)

# Subconjunto de dados de peso depois do tratamento

after <- subset(paired_weight,  group == "after", weight,
                drop = TRUE)

# Plote os dados emparelhados

library(PairedData)

pd <- paired(before, after)
pd
plot(pd, type = "profile") + theme_bw()

# Calcule o teste

res <- wilcox.test(weight ~ group, data = paired_weight, 
                   paired = TRUE)
res

# O p-value do teste é 0.001953, que é menor que o nível
# de significância alfa = 0,05. Podemos concluir que o 
# peso mediano dos camundongos antes do tratamento é 
# significativamente diferente do peso mediano após o 
# tratamento

# se você quiser testar se o peso mediano antes do 
# tratamento é menor do que o peso mediano após o 
# tratamento, use a seguinte função:

wilcox.test(weight ~ group, data = paired_weight, 
            paired = TRUE,alternative = "less")

# Como o p-value > 0.05 conclui-se que o peso mediano antes
# do tratamento é menor que o peso mediano após tratamento

# se você quiser testar se o peso mediano antes do 
# tratamento é maior do que o peso mediano após o
# tratamento, use a seguinte função:

wilcox.test(weight ~ group, data = paired_weight, 
            paired = TRUE,alternative = "greater")

# Como o p-value < 0.05 conclui-se que o peso mediano antes
# do tratamento não é maior do que o peso mediano após o
# tratamento.

######## Teste de Kruskal-Wallis para Comparar #############
#### dois ou mais grupos ou amostras independentes #########

# Carregar dados de pesos de plantas em 3 condições
# experimentais

my_data <- PlantGrowth

# Na terminologia R, a coluna "group" é chamada de fator e 
# as diferentes categorias ("ctr", "trt1", "trt2") são 
# chamadas de níveis de fator. Os níveis são ordenados
# alfabeticamente.

# Mostrar os grupos

levels(my_data$group)

# Se os níveis não estiverem automaticamente na ordem 
# correta, reordene-os da seguinte forma:

my_data$group <- ordered(my_data$group,
                         levels = c("ctrl", "trt1", 
                                    "trt2"))

# Calcule estatísticas resumidas por grupos:

library(dplyr)
group_by(my_data, group) %>%
  summarise(
    count = n(),
    mean = mean(weight, na.rm = TRUE),
    sd = sd(weight, na.rm = TRUE),
    median = median(weight, na.rm = TRUE),
    IQR = IQR(weight, na.rm = TRUE)
  )

# Visualize os dados usando box-plots

library("ggpubr")
ggboxplot(my_data, x = "group", y = "weight", 
          color = "group", palette = c("#00AFBB", "#E7B800",
                                       "#FC4E07"),
          order = c("ctrl", "trt1", "trt2"),
          ylab = "Weight", xlab = "Treatment")

# Gráfico do peso por grupo
# Adicionando barras de erro: mean_se (erro quadrado médio)

library("ggpubr")
ggline(my_data, x = "group", y = "weight", 
       add = c("mean_se", "jitter"), 
       order = c("ctrl", "trt1", "trt2"),
       ylab = "Weight", xlab = "Treatment")


# Cálculo do teste de Kruskal-Wallis

# Queremos saber se existe alguma diferença significativa
# entre os pesos medianos das plantas nas 3 condições 
# experimentais.

kruskal.test(weight ~ group, data = my_data)

qchisq(0.95, 2)
# Como o valor de p (0.01842) é inferior ao nível de 
# significância 0,05, podemos concluir que existem 
# diferenças significativas entre os grupos de tratamento.

### Comparação múltipla de pares entre grupos

# A partir do resultado do teste de Kruskal-Wallis, sabemos
# que há uma diferença significativa entre os grupos, mas 
# não sabemos quais pares de grupos são diferentes.

# É possível usar a função pairwise.wilcox.test () para 
# calcular comparações de pares entre os níveis do grupo
# com correções para testes múltiplos.

pairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group,
                     p.adjust.method = "BH")

# BH é a técnica de ajuste de Benjamini & Hochberg (1995)

# A comparação entre pares mostra que, apenas trt1 e trt2
# são significativamente diferentes pois p < 0.05

# Teste de Dunn com a metodologia de "BY", 
# Benjamini & Yekutieli (2001)

library (dunn.test)
library (PMCMR)
library (PMCMRplus)

dunn.test(my_data$weight, my_data$group, method="by", 
          list=TRUE)

# O teste de Dunn corroborou o teste pela técnica "BH", 
# apenas trt1 e trt2 são significativamente diferentes pois
# p < 0.05

### Teste de Nemenyi com ajustamento de Tukey

#install.packages("PMCMRplus")
library(PMCMRplus)
kwAllPairsNemenyiTest(weight ~ group, data = my_data,
                             dist="Tukey")

# O teste apresentou ligações entre valores e não assegura
# a veracidade dos p-values, mas os demais testes são 
# suficientes. Para outra base de dados este teste pode ser
# conveniente

##### Teste de Friedman para comparar dois ou mais ########
############# grupos/amostras pareadas #################### 

library(tidyverse)
library(ggpubr)
library(rstatix)

# Preparando os dados

data("selfesteem", package = "datarium") 
# escore de autoestima para 10 individuos, em 3 momentos de
# uma dieta

head(selfesteem, 3) # mostra as 3 primeiras linhas

# Reúna as colunas t1, t2 e t3 no formato long. Converta 
# variáveis id e de tempo em variáveis de fator 
# (ou agrupamento):

selfesteem <- selfesteem %>%
  gather(key = "time", value = "score", t1, t2, t3) %>%
  convert_as_factor(id, time)
head(selfesteem, 3)

# Estatísticas de resumo

selfesteem %>%
  group_by(time) %>%
  get_summary_stats(score, type = "common")

# Visualização

ggboxplot(selfesteem, x="time", y="score", add="jitter")

# Calculo da estatística

# Usaremos a função friedman_test() do pacote [rstatix].

res.fried <- selfesteem %>% friedman_test(score ~ time |id)
res.fried

# O escore de autoestima foi diferente estatisticamente
# significante, p-value < 0.05, nos diferentes momentos
# durante a dieta, X2 (2)= qui-quad 2 gl = 18.2, 
# p = 0,000112.

# Tamanho do efeito

selfesteem %>% friedman_effsize(score ~ time |id)

# Um grande tamanho do efeito foi detectado ("large" nos
# resultados), W = 0.91.

# Múltiplas comparações de pares
# A partir do resultado do teste de Friedman, sabemos que
# há uma diferença significativa entre os grupos, mas não
# sabemos quais pares de grupos são diferentes.

# Um teste de Friedman significativo pode ser seguido de
# testes de classificação sinalizada de Wilcoxon aos pares
# para identificar quais grupos são diferentes.

# Observe que os dados devem ser ordenados corretamente
# pela variável (id) para que a primeira observação para o
# tempo t1 seja pareada com a primeira observação para o 
# tempo t2 e assim por diante.

#### Comparações de pares usando teste de postos sinalizados
# de Wilcoxon pareado
# Os p-values são ajustados usando o método de correção  
# múltiplo de Bonferroni.

# Comparações por pares

pwc <- selfesteem %>%
  wilcox_test(score ~ time, paired = TRUE, 
              p.adjust.method = "bonferroni")
pwc

# Todas as diferenças entre pares são estatisticamente
# significativas Todos tem "estrelas" = p-value < 0.05.

# Observe que também é possível realizar compações de 
# pares usando o Teste de Sinal, que pode não ter força 
# para detectar diferenças em conjuntos de dados 
# emparelhados. No entanto, é útil porque tem poucas 
# suposições sobre as distribuições dos dados a serem 
# comparados.

# Comparações de pares usando teste de sinal:

pwc2 <- selfesteem %>%
  sign_test(score ~ time, p.adjust.method = "bonferroni")
pwc2

## O teste corroborou o teste de wilcoxon com exceção entre 
# t2 e t3 não foi significativo

# Relatório final dos testes 

# O escore de autoestima foi estatisticamente significativo 
# nos diferentes momentos usando o teste de Friedman, 
# X2 (2) = 18,2, p = 0,00011.

# O teste de classificação sinalizada de Wilcoxon pairwise 
# entre os grupos revelou diferenças estatisticamente 
# significativas no escore de autoestima entre t1 e t2
# (p = 0,006); t1 e t3 (0,006); t2 e t3 (0,012).

# Visualização: boxplots com p-values

pwc <- pwc %>% add_xy_position(x = "time")
ggboxplot(selfesteem, x="time", y="score", add="point")+
  stat_pvalue_manual(pwc, hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(res.fried,  detailed = TRUE),
    caption = get_pwc_label(pwc)
  )

#################### Fim Aula 1 ############################

################# Início da Aula 2 #########################

############### TESTES PARAMÉTRICOS ######################## 

#### Teste uma amostra (one-sample t test) #################


# Usaremos um conjunto de dados de exemplo contendo o peso 
# de 10 ratos.
# Queremos saber se o peso médio dos ratos difere de 25g?

# install.packages("ggpubr")

library(ggpubr)

load("C:/iaa/data_rats.Rdata" )

####Teste preliminar para verificar as suposições do teste t
# de uma amostra
# Esta é uma amostra grande? - não, porque n<30.
# precisamos verificar se os dados seguem uma distribuição 
# normal.

# Teste de Shapiro-Wilk:
# Hipótese nula: os dados são normalmente distribuídos
# Hipótese alternativa: os dados não são normalmente distrib.

shapiro.test(data_rats$weight) # => p-value = 0.7846

# Vejamos o histograma com kernel
hist(data_rats$weight, # histogram
     col="grey", # column color
     border="black",
     prob = TRUE, # show densities instead of frequencies
     xlab = "weight",
     main = "Weight")
lines(density(data_rats$weight), # density plot
      lwd = 2, # thickness of line
      col = "chocolate3")

# A partir do resultado, o p-value é maior do que o nível 
# de significância 0.05, o que implica que a distribuição
# dos dados não é significativamente diferente da distrib.
# normal. Em outras palavras, podemos assumir a normalidade.

### Teste de t para uma amostra para verificar se a média 
# dos pesos dos ratos da amostra é 25g

res <- t.test(data_rats$weight, mu = 25)
res

# H0: O peso dos ratos é 25g
# HA: 0 peso dos ratos é diferente de 25g

# No resultado acima:
# t é o valor estatístico do teste t (t = -13.788),
# df são os graus de liberdade (df = 9),
# o p-value é o nível de significância do teste t (valor de 
# p = 2.34^{-7}). conf.int é o intervalo de confiança da 
# média a 95% (conf.int = [18,27169, 20,16831]);
# a estimativa é o valor médio da amostra (média = 19.22).

# Interpretação do resultado
# O p-value do teste é 2,34^{-7}, que é menor que o nível
# de significância alfa = 0.05. Pode-se concluir que o peso
# médio dos camundongos é estatisticamente diferente de 25g.


############################################################
# Teste de duas amostras independentes - Unpaired t test  ##


load ("C:/iaa/mw_weight.Rdata")

# Teste preliminar para verificar as suposições do 
# teste t independente

# Premissa 1: as duas amostras são independentes?
# Sim, pois as amostras de homens e mulheres não estão 
# relacionadas.
# Premissa 2: os dados de cada um dos 2 grupos seguem uma
#             distribuição normal?
# Use o teste de normalidade Shapiro-Wilk 
# - Hipótese nula: os dados são normalmente distribuídos 
# - Hipótese alternativa: os dados não estão normalmente
#                         distribuídos

# Usaremos shapiro.test() para calcular o teste Shapiro-Wilk
# para cada grupo de amostras.

# Teste de normalidade Shapiro-Wilk para os pesos masculinos

with(mw_weight, shapiro.test(weight[group == "Man"]))     
# p-value>0.05 (0.1066), logo a amostra possui distribuição
# normal

# Teste de normalidade Shapiro-Wilk para os pesos femininos

with(mw_weight, shapiro.test(weight[group == "Woman"]))     
# p-value>0.05 (0.6101), logo a amostra possui distribuição
# normal

# Pelos resultados dos testes, os dois valores de p são 
# maiores do que o nível de significância 0.05, o que implica
# que a distribuição dos dados não é significativamente 
# diferente da distribuição normal. Em outras palavras, 
# podemos assumir que as amostras tem distribuição normal.

# Observe que se os dados não forem distribuídos normalmente,
# é recomendável usar outro teste de duas amostras não 
# paramétrico.

# Premissa 3. As duas populações têm as mesmas variâncias?
# Usaremos o teste F para testar a homogeneidade nas 
# variâncias. Isso pode ser executado com a função var.test()
# da seguinte maneira:

res.ftest <- var.test(weight ~ group, data = mw_weight)
res.ftest

# H0: As variâncias são iguais 
# HA: As variâncias não são iguais

# O p-value do teste F é p = 0.1714 que é maior do que o nível
# de significância alfa = 0.05. Em conclusão, não há 
# diferença significativa entre as variâncias dos dois 
# conjuntos de dados. Portanto, podemos usar o teste t 
# clássico que assume a igualdade das duas variâncias.

# Pergunta: Existe alguma diferença significativa entre os 
# pesos das mulheres e dos homens?

res <- t.test(weight ~ group, data = mw_weight, 
              var.equal = TRUE)
res

# H0: O peso dos homens não é diferente estatisticamente do 
#     peso das mulheres
# HA: O peso dos homens é diferente estatisticamente do peso
#     das mulheres

# No resultado:
# t é o valor estatístico do teste t (t = 2.784),  df são 
# os graus de liberdade (df = 16),  O p-value é o nível de 
# significância do teste t (valor de p = 0.01327). conf.int 
# é o intervalo de confiança da média a 95% 
# (conf.int = [4.0298 , 29.748]);
# A estimativa da amostra é o valor médio da amostra 
# (média = 68.98889, 52.1).

# O valor de p do teste é 0.01327, que é menor que o nível 
# de significância alfa = 0,05. Pode-se concluir que o peso
# médio dos homens é significativamente diferente do peso 
# médio das mulheres.


############################################################
######### Teste de t para amostras emparelhadas ############


load ("C:/iaa/paired_weight.Rdata")

# Queremos saber se existe alguma diferença significativa nos
# pesos médios dos ratos após o tratamento?

# Estatísticas descritivas

library("dplyr")

group_by(paired_weight, group) %>%
  summarise(
    count = n(),
    mean = mean(weight, na.rm = TRUE),
    sd = sd(weight, na.rm = TRUE)
  )

# Teste preliminar para verificar as suposições do teste t
# pareado

# Premissa 1: as duas amostras estão emparelhadas?
# Sim, uma vez que os dados foram coletados medindo o peso 
# dos mesmos ratos.

# Premissa 2: esta é uma amostra grande?
# Não, n<30. Como o tamanho da amostra não é grande o 
# suficiente (menos de 30), precisamos verificar se as
# diferenças dos pares seguem uma distribuição normal.
# Use o teste de normalidade Shapiro-Wilk

# Hipótese nula: os dados são normalmente distribuídos
# Hipótese alternativa: os dados não são normalmente 
#                       distribuídos

# calcular a diferença

d <- with(paired_weight, 
          weight[group == "before"] - weight[group == "after"])
d

# Shapiro-Wilk normality test for the differences

shapiro.test(d)             # => p-value = 0.6141

# no resultado, o p-value é maior do que o nível de 
# significância 0.05, o que implica que a distribuição
# das diferenças (d) não é significativamente diferente 
# da distribuição normal.
# Em outras palavras, podemos assumir a normalidade.

# Observe que se os dados não forem distribuídos normalmente,
# é recomendável usar um teste de duas amostras emparelhadas 
# não paramétrico.

# Pergunta: Existe alguma mudança significativa no peso dos
# ratos após o tratamento?

res <- t.test(weight ~ group, data = paired_weight, 
              paired = TRUE)
res

# H0: O peso dos ratos é estatisticamente igual
# HA: O peso dos ratos é estatisticamente diferente

# No resultado:
# t é o valor estatístico do teste t (t = 20.883),
# df são os graus de liberdade (df = 9),
# O p-value é o nível de significância do teste t
# (p-value = 6.20^{-9}).
# conf.int é o intervalo de confiança das diferenças das 
# médias com 95%, e também é mostrado 
# (conf.int = [173,42, 215,56])
# A estimativa da amostra para as diferenças das médias 
# entre pares é (média = 194,49).

# O p-value do teste é 6.2^{-9}, que é menor que o nível 
# de significância alfa = 0.05. Podemos então rejeitar a 
# hipótese nula e concluir que o peso médio dos camundongos
# antes do tratamento é significativamente diferente 
# do peso médio após o tratamento.


############################################################
############# Teste One-way ANOVA ##########################

# Aqui, usaremos o conjunto de dados integrado ao R nominado
# PlantGrowth. Ele contém o peso das plantas obtidas sob 
# controle e duas condições de tratamento diferentes.

my_data <- PlantGrowth

# Para ter uma ideia de como são os dados, usamos a função 
# sample_n() [no pacote dplyr]. A função sample_n() escolhe
# aleatoriamente algumas das observações no quadro de dados
# para imprimir:

set.seed(1234)
dplyr::sample_n(my_data, 10)

# Na terminologia R, a coluna "group" é chamada de fator e 
# as diferentes categorias ("ctr", "trt1", "trt2") são 
# chamadas de níveis de fator. Os níveis são ordenados
# alfabeticamente.

levels(my_data$group)

# Calcule algumas estatísticas por grupo-contagem, mídia e sd:

library(dplyr)
group_by(my_data, group) %>%
  summarise(
    count = n(),
    mean = mean(weight, na.rm = TRUE),
    sd = sd(weight, na.rm = TRUE)
  )

### Cálculo do teste ANOVA unilateral ##

# Queremos saber se existe alguma diferença significativa 
# entre os pesos médios das plantas nas 3 condições 
# experimentais.

# A função aov() pode ser usada para responder a esta 
# pergunta. A função summary.aov() é usada para resumir o 
# modelo de análise de variância.

# Cálculo da análise da variância

res.aov <- aov(weight ~ group, data = my_data)

# Sumário estatístico da análise

summary(res.aov)

# O resultado inclui as colunas F-value e Pr(>F) 
# correspondentes ao p-value do teste. Como o p-value é 
# menor que o nível de significância 0.05, pode-se 
# concluir que existem diferenças significativas entre os
# grupos, isso é destacado com "*" no sumário do modelo.

### Comparação múltipla de pares entre as médias dos grupos
# No teste ANOVA unilateral, um valor p significativo indica 
# que algumas das médias do grupo são diferentes, mas não 
# sabemos quais pares de grupos são diferentes. É possível 
# realizar múltiplas comparações de pares, para determinar 
# se a diferença média entre pares específicos do grupo é 
# estatisticamente significativa.

### Comparações de pares múltiplos de Tukey-um teste post-hoc, 
# pode ser usado para mais de 3 grupos
# Como o teste ANOVA é significativo, podemos calcular o 
# teste de Tukey HSD (Tukey Honest Significant Differences,
# função R: TukeyHSD()) 
# para realizar múltiplas comparações de pares entre as 
# médias dos grupos. A função TukeyHD() usa a ANOVA ajustada 
# como argumento.

TukeyHSD(res.aov)

# Parâmetros do teste:
# diff: estatística da diferença entre médias dos dois grupos
# lwr, upr: pontos inferior e superior do intervalo de 
#           confiança 95%
# p adj: valor p após o ajuste para as comparações múltiplas.
# Pode-se ver no resultado, que apenas a diferença entre 
# trt2 e trt1 é significativa com valor p ajustado de 0.012,
# ou seja, trt2 e trt1 são diferentes.

### Múltiplas comparações usando pacote multcomp
# é possível usar a função glht() do pacote [multcomp] para 
# realizar vários procedimentos de comparação para uma ANOVA.
# "glht" significa testes de hipóteses lineares gerais. 
# Use glht() para realizar várias comparações de pares para 
# uma ANOVA unilateral:

library(multcomp)
summary(glht(res.aov, linfct = mcp(group = "Tukey")))

# Novamente foi significativa a diferença entre trt2 e trt1
# com p-value = 0.0121


### Teste t pareado
# A função pairwise.t.test() também pode ser usada para 
# calcular comparações de pares entre níveis de grupo com
# correções para testes múltiplos.

pairwise.t.test(my_data$weight, my_data$group,
                p.adjust.method = "BH")

# O resultado é uma tabela de p-values para as comparações 
# entre pares. Aqui, os p-values foram ajustados pelo método
# de Benjamini-Hochberg. Novamente o teste mostra que existe
# diferença significativa entre trt2 e trt1, as demais não.

# Verifique as suposições da ANOVA: testar a validade!!
# O teste ANOVA assume que os dados são normalmente 
# distribuídos e a variação entre os grupos é homogênea. 
# Podemos verificar isso com alguns gráficos de diagnóstico.
# Também é possível usar o teste de Bartlett ou teste de 
# Levene para verificar a homogeneidade das variâncias.
# Recomenda-se o teste de Levene, que é menos sensível a 
# desvios da distribuição normal. A função leveneTest() 
# [no pacote do car] será usada:

library(car)
leveneTest(weight ~ group, data = my_data)

# No resultado, pode-se ver que o p-value não é menor que
# o nível de significância de 0.05. Isso significa que não
# existe evidências de que a variância entre os grupos seja
# diferente. Portanto, podemos supor a homogeneidade das 
# variâncias nos diferentes grupos de tratamento.

### Relaxando a suposição da homogeneidade da variância
# O teste clássico da ANOVA de um fator clássico requer uma
# suposição de variâncias simlares para todos os grupos. 
# Em nosso exemplo, a suposição de homogeneidade da variância
# se confirmou: pois o teste de Levene não é significativo.
# Mas como fazer na situação em que a suposição de 
# homogeneidade da variância é violada? Usa-se um procedimento
# alternativo que não exige essa suposição.

## Teste de t pareados sem suposição de variâncias iguais

pairwise.t.test(my_data$weight, my_data$group,
                p.adjust.method = "BH", pool.sd = FALSE)

# O teste mostrou os mesmos resultados com p-value<0.05 para 
# trt1 e trt2, ou seja as medianas dos 2 grupos de tratamento
# são diferentes.

### Próximo passo: Teste Shapiro-Wilk para normalidade 
# dos 3 grupos

# Extraíndo os resíduos

aov_residuals <- residuals(object = res.aov )

# Execuntando o teste Shapiro-Wilk

shapiro.test(x = aov_residuals )

# A conclusão do teste de Shapiro-Wilk nos resíduos da ANOVA 
# (W = 0,96, p = 0,43) é de que não se encontra indícios de 
# violação da normalidade. Se a suposição de normalidade 
# fosse rompida, uma opção é usar o teste não-paramétrico
# da soma de ranking de Kruskal-Wallis

#############################################################

############ Testes Repeated-measures ANOVA #################

# É um conjunto de 3 testes:One-way repeated measures ANOVA;
# Two-way repeated measures ANOVA ; e Three-way repeated 
# measures ANOVA. 

### Mesmos indivíduos são medidos mais de uma vez.

########## One-way repeated measures ANOVA ###################

library(tidyverse)
library(ggpubr)
library(rstatix)
library(datarium)


# A base de dados

data("selfesteem", package = "datarium")
head(selfesteem, 3)

# Reunir as colunas t1, t2 e t3 em formato longo
# Converter id e tempo em variáveis de fator

selfesteem <- selfesteem %>%
  gather(key = "time", value = "score", t1, t2, t3) %>%
  convert_as_factor(id, time)
head(selfesteem, 3)

# A ANOVA de medidas repetidas unilaterais pode ser usada
# para determinar se as médias dos escores de autoestima
# são significativamente diferentes entre os três momentos.

# Sumário estatístico

selfesteem %>%
  group_by(time) %>%
  get_summary_stats(score, type = "mean_sd")


# Criar um gráfico "box plot" e adicionar pontos 
# correspondentes aos valores individuais:

bxp <- ggboxplot(selfesteem, x = "time", y = "score", 
                 add = "point")
bxp

## Checando as premissas

# Outliers podem ser facilmente identificados usando métodos 
# de box plot, implementados pela função R identify_outliers()
# [pacote rstatix].

selfesteem %>%
  group_by(time) %>%
  identify_outliers(score)

# observando o resultado do teste, não existem outliers 
# extremos, se houvesse is.extreme seria "TRUE"(se houvesse
# teriamos de deletar). Observe que, na situação em que você tem
# outliers extremos, isso pode ser devido a: erros de entrada 
# de dados; erros de medição; ou valores incomuns. Você pode 
# incluir o outlier na análise de qualquer maneira se não 
# acreditar que o resultado será substancialmente afetado. 
# Isso pode ser avaliado comparando o resultado da ANOVA com  
# e sem o outlier.Também é possível manter os outliers nos 
# dados e realizar um teste ANOVA robusto usando o pacote 
# WRS2.

## A premissa da normalidade

selfesteem %>%
  group_by(time) %>%
  shapiro_test(score)

# O escore de autoestima apresentou distribuição normal em 
# cada tempo, conforme avaliado pelo teste de Shapiro-Wilk
# (p> 0,05).

# Observe que, se o tamanho da sua amostra for maior que 50, 
# o gráfico QQ normal é preferido porque em tamanhos de 
# amostra maiores, o teste de Shapiro-Wilk se torna muito 
# sensível até mesmo a um pequeno desvio da normalidade.

# O gráfico QQ desenha a correlação entre uma variável e a 
# distribuição normal.
# Crie gráficos QQ para cada ponto de tempo:

ggqqplot(selfesteem, "score", facet.by = "time")

# No gráfico, como todos os pontos caem aproximadamente ao
# longo da linha de referência, podemos assumir que a 
# variável tem distribuição normal.

### Suposição de esfericidade ou homogeneidade da amostra

# A suposição de esfericidade é verificada automaticamente
# durante o cálculo do teste ANOVA usando a função 
# anova_test() [pacote rstatix]. O teste de Mauchly é usado
# internamente para avaliar a suposição de esfericidade.
# Usando a função get_anova_table() [pacote rstatix] para 
# extrair a tabela ANOVA, a correção de esfericidade de 
# Greenhouse-Geisser é aplicada automaticamente aos
# fatores que violam a suposição de esfericidade.

res.aov <- anova_test(data = selfesteem, dv = score, 
                      wid = id, within = time)
res.aov
get_anova_table(res.aov)

# O escore de autoestima foi estatisticamente significativo 
# para diferença nos diferentes momentos durante a dieta, 
# F (2, 18) = 55,469, p<0,0001, eta2 [g] = 0,829. A 
# estatística F Indica que estamos comparando a uma 
# distribuição F (teste F); (2, 18) indica os graus de 
# liberdade no numerador (DFn) e no denominador (DFd), 
# respectivamente; 55,469 indica o valor obtido da 
# estatística F, p especifica o p-value, "ges" é o tamanho 
# do efeito generalizado 82.9% (quantidade de variabilidade 
# devido ao fator within-subjects)

## Testes Post-hoc
# Você pode realizar vários testes t pareados por pares 
# entre os níveis dos fatores within-subjects (time). Os 
# p-values são ajustados usando o método de correção
# do teste múltiplo de Bonferroni.

# Comparações por pares

pwc <- selfesteem %>%
  pairwise_t_test(
    score ~ time, paired = TRUE,
    p.adjust.method = "bonferroni"
  )
pwc

# Todas as diferenças entre pares são estatisticamente 
# significativas.

# Resultados
# Pode-se analisar o resultado da seguinte maneira:
# O escore de autoestima foi diferente e estatisticamente 
# significativo nos diferentes tempos. As análises post-hoc 
# com ajuste de Bonferroni revelaram que todas as diferenças
# aos pares, entre os pontos no tempo, foram diferentes e 
# estatisticamente significativas (p < 0.05).

# Visualização: box plots com p-values
pwc <- pwc %>% add_xy_position(x = "time")
bxp + stat_pvalue_manual(pwc) +
  labs(subtitle = get_test_label(res.aov,
                                 detailed = TRUE),
       caption = get_pwc_label(pwc)
  )

########### Two-way repeated measures ANOVA ###############

## Preparando a base de dados

set.seed(123)
data("selfesteem2", package = "datarium")
selfesteem2 %>% sample_n_by(treatment, size = 1)

# Reúna as colunas t1, t2 e t3 no formato longo.
# Converta id e tempo em variáveis de fator

selfesteem2 <- selfesteem2 %>%
  gather(key = "time", value = "score", t1, t2, t3) %>%
  convert_as_factor(id, time)

# Inspecione algumas linhas aleatórias dos dados por grupos

set.seed(123)
selfesteem2 %>% sample_n_by(treatment, time, size = 1)


# Neste exemplo, o efeito do "tempo" na pontuação da 
# autoestima é nossa variável focal, essa é nossa principal
# preocupação. Porém, pensa-se que o efeito do "tempo" será
# diferente se o tratamento for realizado ou não. Nesse 
# cenário, a variável "tratamento" é considerada como 
# variável moderadora.

# Estatísticas de resumo
# Agrupe os dados por tratamento e tempo e, em seguida, 
# calcule algumas estatísticas resumidas da variável de 
# pontuação: média e desvio padrão.

selfesteem2 %>%
  group_by(treatment, time) %>%
  get_summary_stats(score, type = "mean_sd")


## Visualização
# Crie box plots coloridos do score por grupos de 
# tratamento:

bxp <- ggboxplot(
  selfesteem2, x = "time", y = "score",
  color = "treatment", palette = "jco"
)
bxp


### Checagem de premissas
# Outliers

selfesteem2 %>%
  group_by(treatment, time) %>%
  identify_outliers(score)


# Não existem outliers extremos.

### Suposição de normalidade
# Cálculo do Teste de Shapiro-Wilk para cada combinação de
# níveis de fator:

selfesteem2 %>%
  group_by(treatment, time) %>%
  shapiro_test(score)

# O escore de autoestima apresentou distribuição normal em 
# cada momento (p> 0.05), exceto para o fator ctr em t1.

# Criar o gráfico QQ para cada grupo:

ggqqplot(selfesteem2, "score", ggtheme = theme_bw()) +
  facet_grid(time ~ treatment, labeller = "label_both")

# No gráfico, como todos os pontos caem aproximadamente ao 
# longo da linha de referência, podemos assumir normalidade.

### Cálculo do teste Two-way repeated measures ANOVA 

res.aov <- anova_test(
  data = selfesteem2, dv = score, wid = id,
  within = c(treatment, time)
)
res.aov

get_anova_table(res.aov)

# Existe uma interação bidirecional estatisticamente 
# significativa entre o tratamento e o tempo, 
# F (2, 22) = 30,424, p < 0,05.


### Testes Post-hoc
# Uma interação bidirecional significativa indica que o 
# impacto que um fator (por exemplo, tratamento) tem sobre
# a variável de resultado (no exemplo, pontuação de 
# autoestima) depende do nível do outro fator (por exemplo,
# tempo) (e vice-versa). Portanto, você pode decompor uma 
# interação bidirecional significativa em:

# Efeito principal simples: execute o modelo unilateral da 
# primeira variável (fator A) em cada nível da segunda 
# variável (fator B),

# Comparações de pares simples: se o efeito principal 
# simples for significativo, execute várias comparações de
# pares para determinar quais grupos são diferentes.

# Para uma interação bidirecional não significativa, você
# precisa determinar se existe algum efeito principal 
# estatisticamente significativo no resultado da ANOVA.

### Procedimento para uma interação bidirecional significativa 
# Efeito do tratamento. Em nosso exemplo, analisaremos o
# efeito do tratamento na pontuação da autoestima em cada 
# momento.

# Observe que a variável do fator de tratamento possui 
# apenas dois níveis ("ctr" e "Diet"); assim, o teste ANOVA 
# e o teste t pareado fornecerão os mesmos p-values.

# Efeito do tratamento em cada ponto no tempo

one.way <- selfesteem2 %>%
  group_by(time) %>%
  anova_test(dv = score, wid = id, within = treatment) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
one.way

# Resultado: O efeito do tratamento é significativo nos 
# tempos t2 e t3 Considerando o p-value ajustado de 
# Bonferroni (p.adj), verifica-se que o simples efeito 
# principal do tratamento não foi significativo no momento 
# t1 (p = 1). Torna-se significativo em t2 (p = 0,036) e 
# t3 (p = 0,00051).

# Comparações de pares entre grupos de tratamento

pwc <- selfesteem2 %>%
  group_by(time) %>%
  pairwise_t_test(
    score ~ treatment, paired = TRUE,
    p.adjust.method = "bonferroni"
  )
pwc

# As comparações pareadas mostram que a pontuações média de 
# autoestima foi significativamente diferente entre ctr e 
# o grupo Dieta em t2 (p = 0,12) e t3 (p = 0,00017), mas 
# não em t1 (p = 0,552).

# Efeito do tempo. 
# Observe que também é possível realizar a mesma análise
# para a variável tempo em cada nível de tratamento. Você 
# não precisa necessariamente fazer essa análise.

# Efeito do tempo em cada nível de tratamento

one.way2 <- selfesteem2 %>%
  group_by(treatment) %>%
  anova_test(dv = score, wid = id, within = time) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
one.way2

# você pode ver que o efeito do tempo é significativo apenas
# para o controle, F (2, 22) = 39,7, p <0,05. 

# Comparações pareadas entre pontos no tempo

pwc2 <- selfesteem2 %>%
  group_by(treatment) %>%
  pairwise_t_test(
    score ~ time, paired = TRUE,
    p.adjust.method = "bonferroni"
  )
pwc2

# As comparações entre pares mostram que todas as 
# comparações entre os pontos de tempo foram 
# estatisticamente significativas para o grupo de controle,
# mas não para o grupo de tratamento (dieta).

### Procedimento para interação bidirecional não significat.
# Se a interação não for significativa, você precisa 
# interpretar os efeitos principais de cada uma das duas 
# variáveis: tratamento e tempo. Um efeito principal 
# significativo pode ser conseguido com comparações de pares.

# Comparações de teste t pareado:

# comparações para a variável tratamento

selfesteem2 %>%
  pairwise_t_test(
    score ~ treatment, paired = TRUE, 
    p.adjust.method = "bonferroni"
  )

# comparações para a variável tempo

selfesteem2 %>%
  pairwise_t_test(
    score ~ time, paired = TRUE, 
    p.adjust.method = "bonferroni"
  )

# Todas as comparações pareadas são significantes.

## Relatório de resultados
# Podemos relatar o resultado da seguinte maneira:
# Uma ANOVA de medidas repetidas de duas vias foi realizada
# para avaliar o efeito de diferentes tratamentos de dieta 
# ao longo do tempo no escore de autoestima.

# Houve uma interação estatisticamente significativa entre
# o tratamento e o tempo no escore de autoestima, 
# F (2, 22) = 30,424, p<0,05. 
# Com isso, o efeito da variável de tratamento foi analisado
# em cada momento. Os p-values foram ajustados usando o 
# método de correção pelo teste múltiplo de Bonferroni. 
# O efeito do tratamento foi significativo em t2 (p = 0,036)
# e t3 (p = 0,00051), mas não no momento t1 (p = 1).

# As comparações pareadas, usando o teste t pareado, mostram
# que a pontuação média da autoestima foi significativamente
# diferente entre ctr e dieta nos momentos t2 (p = 0,012) e 
# t3 (p = 0,00017), mas n?o em t1 (p = 0.55).

# Visualização: box plots com p-values
pwc <- pwc %>% add_xy_position(x = "time")
bxp + 
  stat_pvalue_manual(pwc, tip.length = 0, hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(res.aov, detailed = TRUE),
    caption = get_pwc_label(pwc)
  )


######### Three-way repeated measures ANOVA ################

## Preparação dos dados

# Usaremos o conjunto de dados de emagrecimento 
# [pacote datarium]. Neste estudo, um pesquisador avaliou
# os efeitos da dieta e dos exercícios na perda de peso em
# 10 indivíduos sedentários. Os participantes foram incluídos
# em quatro ensaios: (1) sem dieta e sem exercícios; 
# (2) dieta apenas; (3) exercícios apenas; e (4) dieta e
# exercícios combinados.
# Cada participante realizou todas as quatro tentativas. A 
# ordem dos testes foi contrabalançada e foi concedido tempo
# suficiente entre os testes para permitir que quaisquer 
# efeitos dos testes anteriores se dissipassem.
# Cada tentativa durou nove semanas e a pontuação da perda
# de peso foi medida no início (t1), no ponto médio (t2) e 
# no final (t3) de cada tentativa.
# A ANOVA de três medidas repetidas pode ser realizada para
# determinar se existe interação significativa entre dieta,
# exercícios e tempo, no escore de perda de peso.

# Preparando os dados

library(tidyverse)
library(ggpubr)
library(rstatix)
library(datarium)


set.seed(123)
data("weightloss", package = "datarium")
weightloss %>% sample_n_by(diet, exercises, size = 1)

# Reúna as colunas t1, t2 e t3 no formato longo.
# Converta id e tempo em variáveis de fator

weightloss <- weightloss %>%
  gather(key = "time", value = "score", t1, t2, t3) %>%
  convert_as_factor(id, time)

# Inspecione algumas linhas dos dados por grupos 
# aleatoriamente

set.seed(123)
weightloss %>% sample_n_by(diet, exercises, time, size = 1)


# Neste exemplo, o efeito "tempo" é nossa variável focal, 
# essa é nossa principal preocupação.
# Pensa-se que o efeito "tempo" no escore de perda de peso 
# dependerá de dois outros fatores, "dieta" e "exercícios", 
# chamados de variáveis moderadoras.

### Estatísticas de resumo

# Agrupe os dados por dieta, exercícios e tempo e em seguida
# calcule algumas estatísticas de resumo da variável de 
# pontuação: média e sd (desvio padrão)

weightloss %>%
  group_by(diet, exercises, time) %>%
  get_summary_stats(score, type = "mean_sd")

### Visualização

# Criar box plots:

bxp <- ggboxplot(
  weightloss, x = "exercises", y = "score",
  color = "time", palette = "jco",
  facet.by = "diet", short.panel.labs = FALSE
)
bxp

# Checando as premissas

# Outliers

weightloss %>%
  group_by(diet, exercises, time) %>%
  identify_outliers(score)

# Não existem outliers extremos.


### Suposição de normalidade

# Cálculo do teste de Shapiro-Wilk para cada combinação 
# de níveis dos fatores:

weightloss %>%
  group_by(diet, exercises, time) %>%
  shapiro_test(score)

# O escore de perda de peso é distribuído normalmente, 
# conforme avaliado pelo teste de normalidade de 
# Shapiro-Wilk (p> 0,05).

# Criar QQ plot para cada grupo:

ggqqplot(weightloss, "score", ggtheme = theme_bw()) +
  facet_grid(diet+exercises~time, labeller="label_both")

# No gráfico, como todos os pontos caem aproximadamente ao
# longo da linha de referência, podemos assumir normalidade.


#### Cálculo do teste para homogeneidade da amostra

res.aov <- anova_test(
  data = weightloss, dv = score, wid = id,
  within = c(diet, exercises, time)
)
res.aov
get_anova_table(res.aov)

# A partir do resultado, pode-se ver que existem interações
# tripartidas estatisticamente significativas entre dieta,
# exercícios e tempo,F (2, 22) = 14,246, p<0,05.
# Observe que, se a interação de três vias não for 
# estatisticamente significativa, você precisa consultar o
# resultado das interações de duas vias.

# Em nosso exemplo, existe iteração bidirecional da dieta 
# estatisticamente significativa: interação com exercícios
# (p <0,0001); 
# Além disso, existe iteração bidirecional de exercícios:
# iteração com tempo (p <0,0001). 
# Interação de duas vias da dieta: iteração com tempo "não"
# foi estatisticamente significativa (p = 0.5).

#### Testes Post-hoc

# Se houver efeito significativo de interação de três vias 
# você pode decompor em:

# 1) Interação bidirecional simples: execute a interação 
#    bidirecional em cada nível da terceira variável,
# 2) Efeito principal simples: execute o modelo unilateral
#    em cada nível da segunda variável, e
# 3) Comparações pareadas simples: execute comparações 
#    pareadas ou outras comparações post-hoc, se necessário.

### Cálculo da interação bidirecional simples

# Vocé é livre para decidir quais duas variáveis formarão 
# as interações bidirecionais simples e qual variável atuará
# como a terceira variável (moderadora). No código R a 
# seguir, consideramos a interação simples de duas vias de 
# exercícios * tempo em cada nível da dieta.

# Agrupe os dados por dieta e analise a interação simples 
# de duas vias entre exercícios e tempo:

# Two-way ANOVA em cada nível de dieta

two.way <- weightloss %>%
  group_by(diet) %>%
  anova_test(dv = score, wid = id, 
             within = c(exercises, time))

# Extrair Tabela anova

get_anova_table(two.way)

# Houve uma interação bidirecional simples estatisticamente
# significativa entre exercícios e tempo para o ensaio 
# "dieta não", F (2, 22) = 28,9, p <0,0001, mas não entre 
# exercícios e tempo para o ensaio "dieta sim",
# F (2, 22) = 2,57, p = 0,099.

# É recomendado ajustar o p-value. Uma abordagem comum
# é aplicar um ajuste de Bonferroni para ajustar o 
# nível no qual você declara a significância estatística.

# Isso pode ser feito dividindo o nível atual em que você
# declara a significância estatística (ou seja, p <0,05) 
# pelo número de interações bidirecionais simples que você
# está computando (ou seja, 2).

# Assim, você só declara uma interação de duas vias como
# estatisticamente significativa quando p <0,025 
# (ou seja, p <0,05 / 2). Aplicando isso ao nosso exemplo
# atual, ainda tiraríamos as mesmas conclusões.

### Calcular efeito principal simples simples

# Uma interação bidirecional simples estatisticamente 
# significativa pode ser seguida de efeitos principais
# simples.

# Em nosso exemplo, você poderia, portanto, investigar o
# efeito do tempo na pontuação de perda de peso em todos
# os níveis de exercícios ou investigar o efeito dos 
# exercícios em todos os níveis de tempo.

# Você só precisará considerar o resultado das análises
# simples do efeito principal para o estudo "dieta não",
# pois essa foi a única interação simples de duas vias
# que foi estatisticamente significativa.

# Agrupe os dados por dieta e exercícios e analise o efeito
# principal simples do tempo. O ajuste de Bonferroni deve  
# ser considerado e a significância estatística deve ser
# aceita no nível de p <0,025 (ou seja, 0,05 dividido pelo
# número de testes (aqui 2) considerados para "dieta: não".

# Efeito do tempo em cada grupo dieta X exercícios

time.effect <- weightloss %>%
  group_by(diet, exercises) %>%
  anova_test(dv = score, wid = id, within = time)

# Extraindo a tabela anova

get_anova_table(time.effect) %>%
  filter(diet == "no")

# Houve um efeito principal simples e estatisticamente 
# significativo do tempo no escore de perda de peso para o
# grupo "dieta: não, exercícios: sim" (p <0,0001), mas não
# para quando nem dieta nem exercícios foram realizados 
# (p = 0,286).

### Calcule comparações simples

# Um efeito principal simples estatisticamente significativo
# pode ser seguido por múltiplas comparações de pares para
# determinar quais médias de grupo são diferentes.

# Agrupe os dados por dieta e exercícios e faça comparações
# aos pares entre os pontos no tempo com o ajuste de 
# Bonferroni:

# Comparações por pares

pwc <- weightloss %>%
  group_by(diet, exercises) %>%
  pairwise_t_test(score ~ time, paired = TRUE, 
                  p.adjust.method = "bonferroni") %>%
  select(-df, -statistic) # Remove alguns detalhes

# Mostrar resultados de comparação para grupos "dieta: não,
# exercícios: sim"

pwc %>% filter(diet == "no", exercises == "yes") %>%
  select(-p)     # remove coluna p, só interessa p. adj.


# Na tabela de comparações de pares, estamos interessados 
# apenas nas comparações simples para grupos "dieta: não,
# exercícios: sim". Em nosso exemplo, existem trés 
# combinações possíveis de diferenças de grupo. Poderíamos
# relatar os resultados da comparação entre pares como segue.

# Todas as comparações pareadas simples foram feitas entre
# os diferentes pontos de tempo para o ensaio "dieta: não,
# exercícios: sim". O ajuste de Bonferroni foi aplicado. 
# A pontuação média de perda de peso foi significativamente
# diferente em todas as comparações nos pontos de tempo
# quando os exercícios são realizados (p <0,05).

#### Relatório do teste

# Uma ANOVA de três medidas repetidas foi realizada para 
# avaliar os efeitos da dieta, exercícios e tempo na perda
# de peso. Houve uma interação de três vias estatisticamente
# significativa entre dieta, exercícios e tempo, 
# F (2, 22) = 14,2, p = 0,00011.

# Para as interações bidirecionais simples e análises de 
# efeitos principais simples, um ajuste de Bonferroni foi
# aplicado levando a significância estatística aceita no
# nível de p<0,025.

# Houve uma interação bidirecional simples estatisticamente
# significativa entre exercícios e tempo para o ensaio 
# "dieta não", F (2, 22) = 28,9, p <0,0001, mas não para o 
# ensaio "dieta sim" ", F (2, 22) = 2,6, p = 0,099.

# Houve um efeito principal simples e estatisticamente 
# significativo do tempo no escore de perda de peso para o
# ensaio "dieta: não, exercícios: sim" (p <0,0001),
# mas não para quando nem dieta nem exercícios foram 
# realizados (p = 0,286).

# Todas as compações pareadas simples foram feitas entre
# os diferentes pontos de tempo para o ensaio "dieta: não,
# exercícios: sim" com um ajuste de Bonferroni aplicado. 
# A pontuação média de perda de peso foi significativamente
# diferente em todas as comparações nos pontos de tempo 
# quando os exercícios são realizados (p <0,05).

# Visualização: box plots com p-values

pwc <- pwc %>% add_xy_position(x = "exercises")
pwc.filtered <- pwc %>% 
  filter(diet == "no", exercises == "yes")
bxp + 
  stat_pvalue_manual(pwc.filtered, tip.length = 0, 
                     hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(res.aov, detailed = TRUE),
    caption = get_pwc_label(pwc)
  )


########################## FIM PARTE 2 ###################

######################### INÍCIO PARTE 3 #################

##########################################################
##### Aplicando a decomposição de séries temporais
###### Série temporal do PIB Mensal BR ###################

#### Instalando e carregando pacotes

pacotes <- c("readxl","plotly","tidyverse","gridExtra",
             "forecast","TTR","smooth","tidyverse", 
             "tsibble", "fable","tsibbledata", "fpp3",
             "urca")

if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
  instalador <- pacotes[!pacotes %in% installed.packages()]
  for(i in 1:length(instalador)) {
    install.packages(instalador, dependencies = T)
    break()}
  sapply(pacotes, require, character = T)
} else {
  sapply(pacotes, require, character = T)
}


load("pib.RData")

# Declarando a série como um objeto da classe ts
pib_ts <- ts(data = pib[, 2],
             start = c(2004, 1),
             end = c(2021, 9),
             frequency = 12)

# Plotagem da série temporal
pib %>%
  ggplot() +
  geom_line(aes(x = Data, y = PIB, group = TRUE, 
                color = "PIB"), size = 1) +
  scale_color_viridis_d() +
  scale_y_continuous(labels = scales::comma) +
  scale_x_date(date_labels = "%m-%Y", 
               date_breaks = "1 year") +
  theme(axis.text.x = element_text(angle = 90,
                                   vjust = 0.4),
        panel.background = element_rect(fill = "white",
                                        color = "black"),
        panel.grid = element_line(color = "grey90"),
        panel.border = element_rect(color = "black",
                                    fill = NA),
        legend.position = "none")

# decompondo o PIB pelo modelo aditivo

decpib <- decompose(x = pib_ts,
                    type = "additive")

# Transformando o objeto decpib num data frame
decpib_df <- data.frame(tempo = pib$Data,
                  serie = unlist(decpib$x),
                  tendencia = unlist(decpib$trend),
                  sazonalidade = unlist(decpib$seasonal),
                  dessazonalizada = pib_ts - decpib$seasonal,
                  erro = unlist(decpib$random)) %>%
  rename(tempo = 1,
         serie = 2,
         tendencia = 3,
         sazonalidade = 4,
         dessazonalizada = 5,
         erro = 6)

#Plotando a decomposição de forma conjunta
decpib_df %>%
  ggplot() +
  geom_line(aes(x = tempo, y = serie, 
                color = "Série"), size = 1.2) +
  geom_line(aes(x = tempo, y = tendencia, 
                color = "Tendência"), size = 1) +
  geom_line(aes(x = tempo, y = sazonalidade, 
                color = "Sazonalidade"), size = 1.2) +
  geom_line(aes(x = tempo, y = erro, 
                color = "Erro"), size = 1) +
  scale_x_date(date_labels = "%m-%Y", 
               date_breaks = "1 year") +
  scale_y_continuous(labels = scales::comma) +
  labs(color = "Legenda:",
       x = NULL,
       y = NULL) +
  scale_color_manual(values = c("#440154FF", "#3CBB75FF",
                                "#39568CFF", "#DCE319FF")) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.4),
        panel.background = element_rect(fill = "white", 
                                        color = "black"),
        panel.grid = element_line(color = "grey90"),
        panel.border = element_rect(color = "black", fill = NA),
        legend.position = "bottom")

# Vizualização de cada componente
decpib$trend
decpib$seasonal
decpib$random

# Gerando objetos para plotagem conjunta

# ==> Série
decpib_df %>%
  ggplot() +
  geom_line(aes(x = tempo, y = serie, 
                color = "Série")) +
  scale_x_date(date_labels = "%m-%Y", 
               date_breaks = "1 year") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Série",
       x = NULL,
       y = NULL) +
  scale_color_manual(values = c("#39568CFF")) +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.4, size = 7),
        panel.background = element_rect(fill = "white",
                                        color = "black"),
        panel.grid = element_line(color = "grey90"),
        panel.border = element_rect(color = "black", 
                                    fill = NA),
        legend.position = "none") -> decomp_serie

# ==> Sazonalidade
decpib_df %>%
  ggplot() +
  geom_line(aes(x = tempo, y = sazonalidade, 
                color = "Sazonalidade")) +
  scale_x_date(date_labels = "%m-%Y", 
               date_breaks = "1 year") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Sazonalidade",
       x = NULL,
       y = NULL) +
  scale_color_manual(values = c("#3CBB75FF")) +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.4, size = 7),
        panel.background = element_rect(fill = "white",
                                        color = "black"),
        panel.grid = element_line(color = "grey90"),
        panel.border = element_rect(color = "black",
                                    fill = NA),
        legend.position = "none") -> decomp_sazonalidade

# ==> Tendência
decpib_df %>%
  ggplot() +
  geom_line(aes(x = tempo, y = tendencia, 
                color = "Tendência")) +
  scale_x_date(date_labels = "%m-%Y", 
               date_breaks = "1 year") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Tendência",
       x = NULL,
       y = NULL) +
  scale_color_manual(values = c("#DCE319FF")) +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.4, size = 7),
        panel.background = element_rect(fill = "white",
                                        color = "black"),
        panel.grid = element_line(color = "grey90"),
        panel.border = element_rect(color = "black", 
                                    fill = NA),
        legend.position = "none") -> decomp_tendencia

# ==> Erro
decpib_df %>%
  ggplot() +
  geom_line(aes(x = tempo, y = erro, color = "Erro")) +
  scale_x_date(date_labels = "%m-%Y", 
               date_breaks = "1 year") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Erro",
       x = NULL,
       y = NULL) +
  scale_color_manual(values = c("#440154FF")) +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.4, size = 7),
        panel.background = element_rect(fill = "white",
                                        color = "black"),
        panel.grid = element_line(color = "grey90"),
        panel.border = element_rect(color = "black", 
                                    fill = NA),
        legend.position = "none") -> decomp_erro

# Observação das partes da decomposição
grid.arrange(decomp_serie,
             decomp_sazonalidade,
             decomp_tendencia,
             decomp_erro,
             ncol = 1)

# Plotando a série dessazonalizada
decpib_df %>%
  ggplot() +
  geom_line(aes(x = tempo, y = serie, color = "Série"),
            size = 1.2) +
  geom_line(aes(x = tempo, y = dessazonalizada, 
                color = "Dessazonalizada"), size = 1) +
  scale_x_date(date_labels = "%m-%Y", 
               date_breaks = "1 year") +
  scale_y_continuous(labels = scales::comma) +
  labs(color = "Legenda:",
       x = NULL,
       y = NULL) +
  scale_color_viridis_d() +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.4),
        panel.background = element_rect(fill = "white",
                                        color = "black"),
        panel.grid = element_line(color = "grey90"),
        panel.border = element_rect(color = "black",
                                    fill = NA),
        legend.position = "bottom")


# Decompondo o PIB pelo modelo multiplicativo

decpib = decompose(pib_ts, type = "multiplicative")
plot(decpib)


# Vizualização de cada componente da decomposição
decpib$trend
decpib$seasonal
decpib$random

#################### MODELO ETS ##########################

# E (Error) T (Trend) S (Season)
# Erro: aditivo (A) ou multiplicativo (M)
# Tendência: nenhuma (N), aditiva (A), multiplicativa (M) 
#            ou amortecida (Ad ou Md)
# Sazonalidade: nenhuma (N), aditiva (A) ou multiplicativa (M)

##############################################################
# Previsão de Consumo Energia Elétrica na região sudeste (Gwh)
# Fonte: http://www.ipeadata.gov.br/Default.aspx
##############################################################

###### Carregando a base de dados de energia

energia <- read_excel("energia.xlsx")

# Separa a coluna 2 que contém os dados de consumo de 
# energia

energia=energia[2]

# Declara os dados como uma série temporal no período  
# de estudo

energia=ts(energia,start=c(1979,1), end=c(2021,9), 
           frequency=12)
energia

# Tamanho da amostra

length(energia)

# Separa a base de dados, um "pedaço" para treinar o
# modelo e outra para prever/testar

# Separação do dataset para treinar e testar o modelo

energiatreino=window(energia,start=c(1979,1), 
                     end=c(2019,12))
plot(energiatreino)
length(energiatreino)

energiateste=window(energia,start=c(2020,1), 
                    end=c(2021,9))
plot(energiateste)
length(energiateste)

###Estimando o modelo ETS

energiatreino.ets <- ets(energiatreino)
summary(energiatreino.ets)

# Fazendo previsão para os 21 períodos da base 
# de teste

energia.ets.forecasts <- forecast.ets(energiatreino.ets, 
                                      h = 21)
summary(energia.ets.forecasts)

# Plotando o gráfico com as previsões

autoplot(energia.ets.forecasts)

ggplotly(
  autoplot(energiatreino)+
    autolayer(energiateste,serie="Valores Reais")+
    autolayer(energia.ets.forecasts$mean, serie="Forecast")+
    scale_colour_viridis_d()+
    scale_y_continuous(labels=scales::comma)+
    theme_bw()
)

# Estatísticas de acurácia na base de teste

accuracy(energia.ets.forecasts$mean,energiateste)

# Plotagem dos resíduos da estimativa

autoplot(energiatreino.ets$residuals)

# Plotando a função de autocorrelação da estimativa

acf(energiatreino.ets$residuals)

# Teste de validação do modelo

# Analisando os resíduos (erros) das previsões
# Condições:
# não podem ser correlacionados; se forem 
# correlacionados ficaram informações nos
# resíduos que deveriam estar no modelo,
# devem possui média zero, caso não possua
# então as previsões são viesadas

Box.test(energiatreino.ets$residuals, lag=1,
         type=c("Ljung-Box"))

# Teste de Ljung-box
# H0: os resíduos são iid (modelo não exibe
#     falhas de ajustes)
# HA: os resíduos não são iid (modelo exibe
#     falhas de ajustes)

# Não desejamos rejeitar H0 (desejo um p-value>0.05)


################## Modelos ARIMA ###################

# Instalação e Carregamento de Todos os Pacotes ----


pacotes <- c("readr","readxl","plotly","tidyverse",
             "gridExtra","forecast","TTR",
             "smooth", "tsibble", "fable","tsibbledata",
             "fpp3","lubridate","urca", "dygraphs", 
             "quantmod","BETS","tseries","FinTS",
             "gridExtra", "scales", "caret","xtable",
             "tsutils","GetBCBData","quantmod","dgof",
             "seasonal")

if(sum(as.numeric(!pacotes %in% installed.packages()))!=0){
  instalador <- pacotes[!pacotes %in% installed.packages()]
  for(i in 1:length(instalador)) {
    install.packages(instalador, dependencies = T)
    break()}
  sapply(pacotes, require, character = T)
} else {
  sapply(pacotes, require, character = T)
}

#############################################################
### Prevendo o consumo de Diesel - Ipeadata
#############################################################

load("C:/iaa/diesel.RData")

# Separando os dados e transformando em série de tempo 

diesel=ts(diesel[2], start = c(1970), end=c(2019), 
            frequency = 1)

# Plotando os dados

autoplot(diesel) +
  theme_bw()

# Teste de sazonalidade

# install.packages("seastests")

library(seastests)

combined_test(diesel)

# Não se aplica porque a série é anual e provavelmente
# não existe sazonalidade anual

diesel.ets <- ets(diesel)
summary(diesel.ets)

# Pelo ETS, não apresentou sazonalidade, pois o modelo ETS
# escolhido foi o Erro multiplicativo, Tendência aditiva e
# Sazonalidade nenhuma (N)
# então podemos crer que não existe sazonalidade

# Separando a base de dados em treino e teste
treinodie=window(diesel, start=c(1970), end=c(2010))
plot(treinodie)
length(treinodie)
testedie=window(diesel, start=c(2011), end=c(2019))
plot(testedie)
length(testedie)

# Analisando a série para a estimativa
ggtsdisplay(treinodie)
acf(treinodie)
pacf(treinodie)

# Teste de Dickey-Fuller
# Ho: A série é não Estacionária
# H1: A série é Estacionária

# vamos ajustar o teste com tendência, uma vez que 
# vimos que a série possui tendência e 1 lag (vimos na PACF)

testeDFdie=ur.df(treinodie, type = 'trend', selectlags='BIC')
testeDFdie
summary(testeDFdie)

# Conclusão: z.lag1 tem p-value 0.526 > 0.05 - 
# Aceito Ho, portanto a série é não estacionária

# Quantas diferenciações são necessárias para tornar
# a série estacionária?

ndiffs(treinodie)

# Resposta = 1 (a série precisa de 1 dierenciação para se
# tornar estacionária). 

# Estimando o modelo por experimentação pelo autoarima

modeldie=auto.arima(treinodie,trace = T)
modeldie

# O auto.arima mostrou que o melhor modelo é um AR(1) I(1)
# MA(0), ou seja, sem média móvel

# Fazendo a previsão do modelo

forecdie<-forecast::forecast(modeldie,h=9)

# Visualizando as previsões (Point Forecast)

forecdie

autoplot(forecdie) +
  theme_bw()

ggplotly(
  autoplot(treinodie)+
    autolayer(testedie,serie="Valores Reais")+
    autolayer(forecdie$mean, serie="Forecast")+
    scale_colour_viridis_d()+
    scale_y_continuous(labels=scales::comma)+
    theme_bw()
)

accuracy(forecdie,testedie)

# Agora que temos um modelo definido precisamos saber se
# o modelo capturou toda a estrutura do processo. Significa
# que devemos checar se os resíduos do modelo estão limpos,
# quer dizer, devemos ter resíduos não autocorrelacionados 
# e normalmente distribuídos

# 1. Teste se os resíduos são não autocorrelacionados
# Teste de Ljung-Box
# H0: independência da ST, isto é, resíduos são não 
#     correlacionados no tempo, são iid (modelo não exibe
#     falhas de ajuste)
# HA: dependência da ST, isto é, resíduos correlacionados
#     (não são iid), modelo com falha de ajuste, o modelo
#      não capturou alguma estrutura que indica um erro 
#      sistemático

autoplot(modeldie$residuals)
checkresiduals(modeldie)

# O p-value foi de 0.06621, logo p-value > 0.05, i.e.
# aceitamos H0, a série é iid e os resíduos são independentes
# não existe falhas de ajuste.

# 2. Teste de Normalidade dos Resíduos
# Teste de Kolmogorv-Smirnov
# H0: Resíduos com comportamento normal
# H1: Resíduos sem normalidade

# Teste de Kolmogorov-Smirnov

ks.test(modeldie$residuals, "pnorm", 
        mean(modeldie$residuals), 
        sd(modeldie$residuals))

# p-value>0.05 - Aceita H0, os resídups são normais

## Testar a estacionariedade da variância significa
## testar se existe efeitos ARCH
# H0: Não Existe Efeitos ARCH
# H1: Existe Efeitos ARCH


ArchTest(modeldie$residuals)

# Se p-value > 0,05 aceita-se a H0, a série não apresenta
# efeitos ARCH

# Se existe existem efeitos Arch devemos utilizar outros 
# modelos tais como os modelos Arch ou Garch (tópico para
# você estudar a parte e se aprofundar)

############################################################
# modelos ARIMA com Sazonalidade - SARIMA, possui os 
# parâmetros P, D e Q Sazonais. Fica SARIMA(p,d,q)(P,D,Q)
############################################################

# Base de dados do Índice de Volume de Vendas de SP

load("C:/iaa/varejo.RData")

varejo=ts(varejo[2], start = c(2000,1), end = c(2021,8), frequency = 12)
plot(varejo)

autoplot(varejo) +
  theme_bw()

# divisão de janelas
treinovarejo=window(varejo, start=c(2000,1), end=c(2019,8))
length(treinovarejo)
testevarejo=window(varejo,start=c(2019,9), end=c(2021,8))
length(testevarejo)

# plotando as duas séries juntas para checagem

autoplot(varejo) +
  autolayer(treinovarejo, series="Treino") +
  autolayer(testevarejo, series="Teste") +
  scale_color_viridis_d() +
  theme_bw()

## Análise da Série
ggtsdisplay(treinovarejo)

# tenho uma prossível sazonalidade

# Vamos ver pelo ETS

varejo.ets <- ets(treinovarejo)
summary(varejo.ets)

# O ETS apresentou uma sazonalidade multiplicativa

# Teste de sazonalidade

# install.packages("seastests")

library(seastests)

combined_test(treinovarejo)

# p-value é = 0 (ou seja, <0.5) então a série tem 
# sazonalidade, então podemos utilizar o SARIMA, caso
# contrário teriamos de usar o ARIMA

# Teste de Estacionariedade

# Teste de Dickey-Fuller
# Ho: A série é não Estacionária
# H1: A série é Estacionária
treinovarejoadf=ur.df(treinovarejo, selectlags = 'BIC',
                      type = 'none')
summary(treinovarejoadf)
treinovarejoadf=ur.df(treinovarejo, selectlags = 'BIC',
                      type = 'drift')
summary(treinovarejoadf)
treinovarejoadf=ur.df(treinovarejo, selectlags = 'BIC',
                      type = 'trend')
summary(treinovarejoadf)

# Não temos certeza se a série é estacionária, os diversos 
# testes ADF obtiveram resultados diferentes

# Vamos ver o que a rotina de detecção de diferenciações nos
# diz !!

ndiffs(treinovarejo)

diftreinovarejo=diff(treinovarejo)
ggtsdisplay(diftreinovarejo)

treinovarejoadfdif=ur.df(diftreinovarejo, type = 'none',
                         selectlags = 'BIC')
summary(treinovarejoadfdif)

treinovarejoadfdif=ur.df(diftreinovarejo, type = 'drift',
                         selectlags = 'BIC')
summary(treinovarejoadfdif)


# A funão auto.arima vai detectar a sazonalidade e tratar 
# como um modelo SARIMA, fazer as diferenciações, etc.

arimavarejo=auto.arima(treinovarejo, trace=T)

#### validação e diagnóstico

checkresiduals(arimavarejo)

# 1. teste de Ljung-Box p-value = 0.5636>0.05, aceitamos H0,
# resíduos não são correlacionados (são iid - modelo não 
# possui falhas de ajustamento)

# 2. Normalidade dos resíduos
ks.test(arimavarejo$residuals, "pnorm", mean(arimavarejo$residuals),
        sd(arimavarejo$residuals))
# p-valor = 0.1164 > 0.05 - Aceita H0, ou seja, resíduos normais

# confirmamos a não existência de autocorrelação serial e não 
# normalidade dos resíduos. Podemos verificar a estacionariedade
# da variãncia, verificar se existe efeitos ARCH

ArchTest(arimavarejo$residuals)

# p-valor 0.1878 > 0.05, aceita-se H0 (não se rejeita a H0) 
# garante não existência de efeitos ARCH (heterocedasticidade)

## Previsao para a série de varejo SP

prevvarejo=forecast::forecast(arimavarejo, h=24)

# Observando os valores da previsão

prevvarejo

autoplot(prevvarejo) +
  theme_bw()

# Estatísticas de acurácia do modelo

accuracy(prevvarejo, testevarejo)

# Gráfico do modelo ajustado com previsões

ggplotly(
  autoplot(treinovarejo)+
    autolayer(testevarejo,serie="Valores Reais")+
    autolayer(prevvarejo$mean, serie="Forecast")+
    scale_colour_viridis_d()+
    scale_y_continuous(labels=scales::comma)+
    theme_bw()
)

